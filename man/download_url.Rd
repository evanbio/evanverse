% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/download_url.R
\name{download_url}
\alias{download_url}
\title{ðŸ“¥ download_url(): Professional Downloader based on curl}
\usage{
download_url(
  url,
  dest = basename(url),
  overwrite = FALSE,
  unzip = FALSE,
  verbose = TRUE,
  timeout = 600,
  headers = NULL,
  resume = FALSE,
  speed_limit = NULL,
  retries = 3
)
}
\arguments{
\item{url}{Character. Full URL to the file (FTP/HTTP/HTTPS/SFTP).}

\item{dest}{Character. Destination file path. Default: basename(url).}

\item{overwrite}{Logical. Whether to overwrite existing files. Default: FALSE.}

\item{unzip}{Logical. Whether to unzip after download (supports .zip/.gz/.tar.gz). Default: FALSE.}

\item{verbose}{Logical. Show download progress. Default: TRUE.}

\item{timeout}{Integer. Download timeout in seconds. Default: 600.}

\item{headers}{Named list. Custom HTTP headers (e.g., Authorization). Default: NULL.}

\item{resume}{Logical. Try to resume interrupted downloads. Default: FALSE.}

\item{speed_limit}{Numeric. Bandwidth limit in bytes/sec (e.g., 500000 = 500KB/s). Default: NULL (no limit).}

\item{retries}{Integer. Number of retry attempts if failed. Default: 3.}
}
\value{
Invisibly returns the downloaded (and optionally unzipped) file path.
}
\description{
A robust and flexible downloader using curl. Supports timeout, headers, resume, bandwidth limit, and retries.
}
